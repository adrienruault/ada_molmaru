{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2: applied ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.mlab as mlab\n",
    "import sklearn.datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from pprint import pprint\n",
    "import random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing of the newspaper dataset\n",
    "\n",
    "#### Loading of the newspaper dataset\n",
    "\n",
    "Firstly we load the newspaper standard dataset from the sklearn library and we print the newspapers categories (targets) that are used for classification in this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils.Bunch'>\n",
      "['DESCR', 'data', 'description', 'filenames', 'target', 'target_names']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18846"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups= fetch_20newsgroups(subset ='all')\n",
    "pprint(type(newsgroups))\n",
    "pprint(dir(newsgroups))\n",
    "len(newsgroups.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training, validation and test set generation\n",
    "\n",
    "In this part we randomly divide the dataset in three parts as follows:\n",
    "- Train set: constituting 80% of the original dataset\n",
    "- Validation set: constituting 10% of the original dataset\n",
    "- Test set: constituting 10% of the original dataset\n",
    "\n",
    "Firstly we get the number of data that will be in each set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_ratio = 0.8\n",
    "test_ratio = 0.1\n",
    "valid_ratio = 0.1\n",
    "\n",
    "data_len = len(newsgroups.filenames)\n",
    "train_len = int(np.floor(train_ratio*data_len))\n",
    "test_len = int(np.floor(test_ratio*data_len))\n",
    "valid_len = int(data_len - (train_len + test_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we use the shuffle function from the random package to shuffle indices and therefore to randomly attribute the observed data to each of the three subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_articles = [i for i in range(data_len)]\n",
    "\n",
    "random.seed(2)\n",
    "random.shuffle(rand_articles)\n",
    "\n",
    "train_subset = rand_articles[0:train_len]\n",
    "test_subset = rand_articles[train_len:train_len+test_len]\n",
    "valid_subset = rand_articles[train_len+test_len:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF computation\n",
    "\n",
    "Now we compute the TF-IDF statistic for the newspaper dataset. To do so we use the `TfidfVectorizer()` function from the `sklearn` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(newsgroups.data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following part we just assign the vectors obtained in the previous step to the train, test and training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_vectors = vectors[train_subset,:]\n",
    "test_vectors = vectors[test_subset,:]\n",
    "valid_vectors = vectors[valid_subset,:]\n",
    "\n",
    "train_target = [newsgroups.target[w] for w in train_subset]\n",
    "test_target = [newsgroups.target[w] for w in test_subset]\n",
    "valid_target = [newsgroups.target[w] for w in valid_subset]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Training \n",
    "\n",
    "#### Grid search\n",
    "\n",
    "Now we compute train a random forest classifier for different combination of parameters. The parameters that are investigated are:\n",
    "- The number of decision trees generated in order to build the random forest.\n",
    "- The maximum depth of each of those decision trees\n",
    "\n",
    "To do so we implement a grid search over the parameters. Therefore we train a random forest for each parameter combination in a two nested for loops. While training random forests for the different combinations of parameters we also compute the train score and the validation score. The validation score will be useful afterwards to select the parameter combination that yields the best prediction. \n",
    "\n",
    "The score computed in this part is the default score implemented in the sklearn classifier for Random Forests: it is the mean accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   11.2s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   14.8s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   17.8s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   22.2s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   25.7s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:   34.1s finished\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:   48.3s finished\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:  1.0min finished\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:   44.7s finished\n",
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:    4.8s finished\n",
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:  1.0min finished\n",
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:    6.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:    5.2s finished\n",
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:  1.5min finished\n",
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:    6.2s finished\n",
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:  1.8min finished\n",
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:    5.7s finished\n",
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:   57.6s finished\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    6.9s finished\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:  1.4min finished\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    6.8s finished\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:  1.7min finished\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    7.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:  2.0min finished\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    7.1s finished\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:  2.4min finished\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    8.3s finished\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    1.1s finished\n"
     ]
    }
   ],
   "source": [
    "parameters = {'n_estimators': [100, 300, 400, 500] , 'max_depth':[25, 30, 35, 40, 45]}\n",
    "train_score = np.zeros((len(parameters['n_estimators']), len(parameters['max_depth'])))\n",
    "valid_score = np.zeros((len(parameters['n_estimators']), len(parameters['max_depth'])))\n",
    "\n",
    "for index_estim, n_estimators in enumerate(parameters['n_estimators']):\n",
    "    for index_depth, max_depth in enumerate(parameters['max_depth']):\n",
    "        rand_forest = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, verbose = 1)\n",
    "        rand_forest.fit(train_vectors, train_target)\n",
    "        train_score[index_estim, index_depth] = rand_forest.score(train_vectors, train_target)\n",
    "        valid_score[index_estim, index_depth] = rand_forest.score(valid_vectors, valid_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scores obtained for the training set and the test set are the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.77889714,  0.78844115,  0.7990456 ,  0.79745493,  0.80965005],\n",
       "       [ 0.79374337,  0.81018028,  0.81972428,  0.81919406,  0.82502651],\n",
       "       [ 0.7921527 ,  0.81177094,  0.81654295,  0.82926829,  0.83297985],\n",
       "       [ 0.79321315,  0.81707317,  0.82396607,  0.82661718,  0.83191941]])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.9225922 ,  0.94421597,  0.96113027,  0.97366676,  0.98023348],\n",
       "       [ 0.94235872,  0.96026798,  0.97174317,  0.9806978 ,  0.98640223],\n",
       "       [ 0.94229239,  0.96132927,  0.97273813,  0.98102945,  0.98726453],\n",
       "       [ 0.94733351,  0.9637835 ,  0.97459538,  0.98182542,  0.98772884]])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heat maps of the scores\n",
    "\n",
    "Now we plot both the validation score and the train score thanks to heat maps. The validation is going to help us choosing the combination of parameters that maximizes the mean accuracy. The train score heat map is just plot to confirm that the train error decreases as both the max tree depth and the number of trees increase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[25, 30, 35, 40, 45]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters['max_depth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Train score')"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUkAAAEWCAYAAADrUmWKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9ddd76d390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUkAAAEWCAYAAADrUmWKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAFf5JREFUeJzt3Xm0ZWV95vHvA8WoSDGLFAottLOi\nKWlsutWA2kZtBFuXIhqk6YCJSUhr4pBlNMa5EwOyktgSJ5wYQhwqDjGIoB0HEBARhVakUcpCEWWU\ngAK//mO/N9wU9751ajj3nHvr+1nrrHP2u999zm/XXvepPZzz7lQVkqS5bTHpAiRpmhmSktRhSEpS\nhyEpSR2GpCR1GJKS1GFIauol2TLJrUkeOOlatPmJ35PUppbk1lmT2wN3AHe16eOr6iMLX5W0YQxJ\njVWSq4H/UVWf7/RZVlV3LlxVm85irl2j8XBbCy7Jm5KckeS0JLcAL0ryhCRfS3JjkmuTnJxkq9Z/\nWZJKsk+b/nCb/9kktyT5apJ95/ms7ZN8NMnP2ntfkGTXNm+XJB9on3dDkr+ftdxLk1zZlvtEkj3X\nquV3klwJXNHaH57k80l+nuSKJP9tnP+GWjiGpCblCOCjwI7AGcCdwAnArsDBwNOB4zvLvxD4E2Bn\n4IfAG+fpdwzDIf8KYBfgd4Db27yPAlsDDwf2AN4JkORpwJ8BzwX2AtYAa58iOAx4PPCoJDsAZwMf\nBHYHjgJOSfKQ/j+BFgNDUpPyz1X1D1V1d1X9S1V9varOr6o7q+oq4BTgSZ3lz6qqC6vqVwwBdsA8\n/X7FELz7VdVdbZlbk+wNHAr8dlXdUFW/rKovtWWOAt5TVZdU1e3Aq4EnJVkx633f0pb7F4bA/G5V\nfbDVfxHwCYaQ1SJnSGpSrpk9keShST6d5MdJbmbYk9u1s/yPZ72+DbjvPP0+AHweODPJj5K8Lcky\nYG/g+qq6aY5lHgD8YGaiqm4GbmDYq5yr/gcBB7fD+RuT3Ag8H9izU78WCUNSk7L2FcN3A5cx7PHd\nD3gdkI3+kGEP8U+r6mHAf2I4zD+KIeR2TXK/ORZbwxB8ALTD6Z2AH81T/zXAOVW1fNbjvlX1uxtb\nvybPkNS02AG4CfhFkofRPx85siSHJHlkki2AmxkOv++qqmsY9jD/OsnyJFsleWJb7DTg2CSPTrIN\n8Fbg/1TV6nk+ZhXwiCQvbO+zVZIDPSe5NBiSmhavAI4GbmHYqzxjE73vA4CPMQTktxmC8bQ270Xt\n+bvAT4DfA6iqf2Q43P84cC3wQIa9zzm1Q/b/0t7vWoZTAW8FttlE66AJ8nuSktThnqQkdRiSktRh\nSEpShyEpSR3LJl3AxkhSSzHlHznpAsZoq6U62NluS/lC9m6TLmAsLrpo9fVVtc6VW9QhuQWw7aSL\nGIPPTbqAMbr/ayZdwZi89EHr7rNoHTfpAsYi+cMfrLuXh9uS1GVISlKHISlJHYakJHUYkpLUYUhK\nUochKUkdhqQkdRiSktRhSEpShyEpSR2GpCR1GJKS1GFISlKHISlJHYakJHUYkpLUYUhKUochKUkd\nhqQkdRiSktRhSEpSx9hCMsn7klyX5LJZbTsnOTvJ99rzTq09SU5OcmWSS5M8blx1SdL6GOee5AeA\np6/V9mrgnKraHzinTQP8BrB/exwHvGuMdUnSyMYWklX1JeDnazU/Gzi1vT4VOHxW+wdr8DVgeZI9\nx1WbJI1qoc9J7lFV1wK0591b+17ANbP6rW5tkjRRyyZdQJM52mrOjslxDIfkcy4kSZvSQu9J/mTm\nMLo9X9faVwN7z+q3Algz1xtU1SlVtbKqVhqSksZtoUNyFXB0e3008MlZ7b/ZrnIfBNw0c1guSZM0\ntsPtJKcBTwZ2TbIaeD3wNuDMJMcCPwSe17p/BngGcCVwG3DMuOqSpPUxtpCsqiPnmXXoHH0LeNm4\napGkDeUvbiSpw5CUpA5DUpI6DElJ6jAkJanDkJSkDkNSkjoMSUnqMCQlqcOQlKQOQ1KSOgxJSeow\nJCWpw5CUpA5DUpI6DElJ6jAkJanDkJSkDkNSkjoMSUnqMCQlqWNsd0tcCA8Fzpx0EWNw/5MmXcEY\nvXT7SVcwJr8/6QLG6PmTLmBM/nCkXu5JSlKHISlJHYakJHUYkpLUYUhKUochKUkdhqQkdRiSktRh\nSEpShyEpSR2GpCR1GJKS1GFISlKHISlJHYakJHUYkpLUMVJIJjmuNy1JS9Woe5JZx7QkLUkjhWRV\nvbs3LUlL1TpDMskJSe6XwXuTXJzkaQtRnCRN2ih7kv+9qm4GngbsBhwDvG2sVUnSlBglJGfOPz4D\neH9VfRPPSUraTIwSkhcl+SeGkPxckh2Au8dbliRNh1Huu30scABwVVXdlmQXhkNuSVryRtmTLODh\n3HP39fsA265roSTbJrkgyTeTfDvJG1r7vknOT/K9JGck2bq1b9Omr2zz99mgNZKkTWiUkPwb4AnA\nkW36FuCvR1juDuCQqnoMw57o05McBLwdOLGq9gduYNhTpT3fUFX7ASe2fpI0UaOE5H+oqpcBtwNU\n1Q3A1utaqAa3tsmt2qOAQ4CzWvupwOHt9bPbNG3+oUm8QCRpokYJyV8l2ZIh4EiyGyNeuEmyZZJL\ngOuAs4HvAzdW1Z2ty2pgr/Z6L+AagDb/JmCXOd7zuCQXJrnwhlGKkKSNMEpIngx8HNgjyZuBfwbe\nMsqbV9VdVXUAsAI4EHjYXN3a81x7jXWvhqpTqmplVa3caZQiJGkjrPPqdlV9JMlFwKEMQXZ4VV2+\nPh9SVTcmOQ84CFieZFnbW1wBrGndVgN7A6uTLAN2BH6+Pp8jSZvaqANc7ArcVlV/BVyfZN91LZBk\ntyTL2+vtgKcAlwPnAs9t3Y4GPtler2rTtPlfqKp77UlK0kJa555kktcDK4GHAO9nuADzYeDgdSy6\nJ3BqO5+5BXBmVX0qyXeA05O8CfgG8N7W/73Ah5JcybAH+YINWB9J2qRG+TL5EcBjgYsBqmpN+9VN\nV1Vd2pZbu/0qhvOTa7ffDjxvhHokacGMcrj9y3bYO3N1+z7jLUmSpscoIXlmknczXHD5LeDzwN+O\ntyxJmg6jXN3+iyRPBW5mOC/5uqo6e+yVSdIU6IZku+jyuap6CsOXwSVps9I93K6qu4Dbkuy4QPVI\n0lQZ5er27cC3kpwN/GKmsap+f/5FJGlpGCUkP90es/klb0mbhVFCcnlVvXN2Q5ITxlSPJE2VUb4C\ndPQcbS/ZxHVI0lSad08yyZHAC4F9k6yaNWsH4GfjLkySpkHvcPsrwLUMg1u8Y1b7LcCl4yxKkqbF\nvCFZVT8AfsBw6wZJ2iyNOlSaJG2WDElJ6pg3JJOc0569a6GkzVbvws2eSZ4EHJbkdNa6B01VXTzW\nyiRpCvRC8nXAqxnuQ/OXa82buTWsJC1pvavbZwFnJfmTqnrjAtYkSVNjlPEk35jkMOCJrem8qvrU\neMuSpOmwzqvbSd4KnAB8pz1OaG2StOSNMsDFM4EDqupugCSnMtzl8DXjLEySpsEoIQmwnOE2rwAO\nwDtu20+6gHFaPukCxmTUP6XFaKlus9GMsmXfCnwjybkMXwN6Iu5FStpMjHLh5rQk5wGPZwjJV1XV\nj8ddmCRNg5GOEarqWmDVOjtK0hLjb7clqcOQlKSObkgm2SLJZQtVjCRNm3Xdd/tu4JtJHrhA9UjS\nVBnlws2ewLeTXMC/ve/2YWOrSpKmxCgh+YaxVyFJU2qU70l+McmDgP2r6vNJtge2HH9pkjR5owxw\n8VvAWcC7W9NewCfGWZQkTYtRvgL0MuBg4GaAqvoesPs4i5KkaTFKSN5RVb+cmUiyjGFkckla8kYJ\nyS8m+WNguyRPBf4O+IfxliVJ02GUkHw18FPgW8DxwGeA146zKEmaFqNc3b67DbR7PsNh9v+tKg+3\nJW0W1hmSSZ4J/G/g+wxDpe2b5Piq+uy4i5OkSRvly+TvAH69qq4ESPJg4NOAISlpyRvlnOR1MwHZ\nXAVcN6Z6JGmqzLsnmeQ57eW3k3wGOJPhnOTzgK8vQG2SNHG9w+3/Ouv1T4Antdc/BXYaW0WSNEXm\nDcmqOmYhC5GkaTTK1e19gd8D9pnd36HSJG0ORrm6/QngvQy/srl7fT8gyZbAhcCPqupZLXRPB3YG\nLgZeXFW/TLIN8EHg14CfAc+vqqvX9/MkaVMa5er27VV1clWdW1VfnHmsx2ecAFw+a/rtwIlVtT9w\nA3Bsaz8WuKGq9gNObP0kaaJGCcl3Jnl9kickedzMY5Q3T7ICeCbwnjYd4BCGodcATgUOb6+f3aZp\n8w9t/SVpYkY53H4U8GKGcJs53K42vS4nAa8EdmjTuwA3VtWdbXo1w/iUtOdrAKrqziQ3tf7Xz37D\nJMcBx8FwXwlJGqdRQvII4N/NHi5tFEmexfBF9IuSPHmmeY6uNcK8exqqTgFOAXhE4m/IJY3VKCH5\nTWA56/8rm4OBw5I8A9gWuB/DnuXyJMva3uQKYE3rvxrYG1jdxqzcEfj5en6mJG1So5yT3AO4Isnn\nkqyaeaxroap6TVWtqKp9gBcAX6iqo4Bzgee2bkcDn2yvV7Vp2vwvONqQpEkbZU/y9Zv4M18FnJ7k\nTcA3GL5eRHv+UJIrGfYgX7CJP1eS1ttId0vc2A+pqvOA89rrq4AD5+hzO8PvwiVpaozyi5tbuOcC\nytbAVsAvqup+4yxMkqbBKHuSO8yeTnI4c+wJStJSNMqFm3+jqj7BaN+RlKRFb5TD7efMmtwCWIm3\nlJW0mRjl6vbscSXvBK5m+AmhJC15o5yTdFxJSZut3u0bXtdZrqrqjWOoR5KmSm9P8hdztN2HYUiz\nXQBDUtKS17t9wztmXifZgWFcyGMYBsx9x3zLSdJS0j0nmWRn4OXAUQxjPT6uqm5YiMIkaRr0zkn+\nOfAchmHJHlVVty5YVZI0JXpfJn8F8ADgtcCaJDe3xy1Jbl6Y8iRpsnrnJNf71ziStNQYhJLUYUhK\nUochKUkdhqQkdRiSktRhSEpShyEpSR2GpCR1jDLo7tTabgt4xLaTrmIM7j/pAsZpxaQLGJP7TrqA\nMVrUMbHR3JOUpA5DUpI6DElJ6jAkJanDkJSkDkNSkjoMSUnqMCQlqcOQlKQOQ1KSOgxJSeowJCWp\nw5CUpA5DUpI6DElJ6jAkJanDkJSkDkNSkjoMSUnqMCQlqcOQlKQOQ1KSOgxJSeoYa0gmuTrJt5Jc\nkuTC1rZzkrOTfK8979Tak+TkJFcmuTTJ48ZZmySNYiH2JH+9qg6oqpVt+tXAOVW1P3BOmwb4DWD/\n9jgOeNcC1CZJXZM43H42cGp7fSpw+Kz2D9bga8DyJHtOoD5J+lfjDskC/inJRUmOa217VNW1AO15\n99a+F3DNrGVXtzZJmphlY37/g6tqTZLdgbOTXNHpmzna6l6dhrA9DuCBcy0hSZvQWPckq2pNe74O\n+DhwIPCTmcPo9nxd674a2HvW4iuANXO85ylVtbKqVu5mSEoas7GFZJL7JNlh5jXwNOAyYBVwdOt2\nNPDJ9noV8JvtKvdBwE0zh+WSNCnjPNzeA/h4kpnP+WhV/WOSrwNnJjkW+CHwvNb/M8AzgCuB24Bj\nxlibJI1kbCFZVVcBj5mj/WfAoXO0F/CycdUjSRvCX9xIUochKUkdhqQkdRiSktRhSEpShyEpSR2G\npCR1GJKS1GFISlKHISlJHYakJHUYkpLUYUhKUochKUkdhqQkdRiSktRhSEpShyEpSR2GpCR1GJKS\n1GFISlKHISlJHRnu5Lo4Jfkp8IMF+rhdgesX6LMW2lJdN9dr8VnIdXtQVe22rk6LOiQXUpILq2rl\npOsYh6W6bq7X4jON6+bhtiR1GJKS1GFIju6USRcwRkt13VyvxWfq1s1zkpLU4Z6kJHUYkpLUYUjO\nIcneSc5NcnmSbyc5obX/aZIfJbmkPZ4x6VrXR5Jtk1yQ5Jttvd7Q2vdNcn6S7yU5I8nWk651fXTW\n6wNJ/t+s7XXApGvdUEm2TPKNJJ9q04t6m82YY72mbpsZknO7E3hFVT0MOAh4WZKHt3knVtUB7fGZ\nyZW4Qe4ADqmqxwAHAE9PchDwdob12h+4ATh2gjVuiPnWC+CPZm2vSyZX4kY7Abh81vRi32Yz1l4v\nmLJtZkjOoaquraqL2+tbGDbiXpOtauPV4NY2uVV7FHAIcFZrPxU4fALlbbDOei0JSVYAzwTe06bD\nIt9mcO/1mlaG5Dok2Qd4LHB+a/rdJJcmeV+SnSZW2AZqhzeXANcBZwPfB26sqjtbl9Uswv8Q1l6v\nqprZXm9u2+vEJNtMsMSNcRLwSuDuNr0LS2Cbce/1mjFV28yQ7EhyX+DvgT+oqpuBdwEPZjikuxZ4\nxwTL2yBVdVdVHQCsAA4EHjZXt4WtauOtvV5JHgm8Bngo8HhgZ+BVEyxxgyR5FnBdVV00u3mOrotq\nm82zXjCF28yQnEeSrRgC8iNV9TGAqvpJ+2O8G/hbhpBZlKrqRuA8hnOuy5Msa7NWAGsmVdfGmrVe\nT2+nTaqq7gDez+LcXgcDhyW5Gjid4TD7JBb/NrvXeiX58DRuM0NyDu2cz3uBy6vqL2e17zmr2xHA\nZQtd28ZIsluS5e31dsBTGM63ngs8t3U7GvjkZCrcMPOs1xUz26ttz8NZZNsLoKpeU1Urqmof4AXA\nF6rqKBb5NptnvV40jdts2bq7bJYOBl4MfKud5wL4Y+DI9pWEAq4Gjp9MeRtsT+DUJFsy/Ad5ZlV9\nKsl3gNOTvAn4BsN/EIvJfOv1hSS7MRyeXgK8dJJFbmKvYnFvs/l8ZNq2mT9LlKQOD7clqcOQlKQO\nQ1KSOgxJSeowJCWpw5DUgkhSST40a3pZkp/OjP6yiT/rvCQbdDOpJIfPGsxko95LS4MhqYXyC+CR\n7cveAE8FfjTBeuZzOPDwdfbSZsOQ1EL6LMOoLwBHAqfNzEhyYJKvtLEFv5LkIa395Une114/Ksll\nSbaf/aZJtktyehsU4Qxgu1nznpbkq0kuTvJ37ff4JLk6ydvbOJQXJNkvyX8EDgP+vI1l+OD2Ns9r\nfb6b5D+P6d9GU8qQ1EI6HXhBkm2BR3PPyEoAVwBPrKrHAq8D3tLaTwL2S3IEw295j6+q29Z6398G\nbquqRwNvBn4NIMmuwGuBp1TV44ALgZfPWu7mqjoQ+CvgpKr6CrCKe8Yz/H7rt6z1+wPg9e29H5Bk\nsY0nqg3gzxK1YKrq0jb03JHA2gGzI8NPC/dn+NnnVm2Zu5O8BLgUeHdVfXmOt34icPKsz7i0tR/E\ncOj85eGnwGwNfHXWcqfNej6xU/rH2vNFwD7tc9YAi2pkem0YQ1ILbRXwF8CTGcZFnPFG4NyqOqIF\n6Xmz5u0P3Ao8oPO+c/2+NgxjSx45wjK93+fe0Z7vwr+ZzY6H21po7wP+rKq+tVb7jtxzIeclM41J\ndgTeybC3uEuS53JvXwKOav0fyXAoD/A14OAk+7V52yf597OWe/6s55k9zFuAHdZ/tbRUGZJaUFW1\nuqreOces/wW8NcmXgS1ntZ8I/E1VfZfhPi5vS7L7Wsu+C7hvO8x+JXBB+6yfMgTuaW3e1xgGdJ2x\nTZLzGe6z8j9b2+nAH7ULSA9mHp6T3Hw4CpA2S22w15VVdf2ka9F0c09Skjrck5SkDvckJanDkJSk\nDkNSkjoMSUnqMCQlqeP/A0GIW3II8yE5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9ddd7390b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.ticker as ticker\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "# We need to draw the canvas, otherwise the labels won't be positioned and \n",
    "# won't have values yet.\n",
    "fig.canvas.draw()\n",
    "plt.imshow(valid_score, cmap='hot')\n",
    "ax.set_yticklabels([''] + parameters['n_estimators'])\n",
    "ax.set_xticklabels([''] + parameters['max_depth'])\n",
    "plt.xlabel('Max depth: ')\n",
    "plt.ylabel('Number of trees: ')\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "plt.title('Validation score')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "# We need to draw the canvas, otherwise the labels won't be positioned and \n",
    "# won't have values yet.\n",
    "fig.canvas.draw()\n",
    "plt.imshow(train_score, cmap='hot')\n",
    "ax.set_yticklabels([''] + parameters['n_estimators'])\n",
    "ax.set_xticklabels([''] + parameters['max_depth'])\n",
    "plt.xlabel('Max depth: ')\n",
    "plt.ylabel('Number of trees: ')\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "plt.title('Train score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter selection\n",
    "\n",
    "The cell below shows the best combination that yields the least validation error over the tested parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best number of trees is: 400\n",
      "The best maximal tree depth is: 45\n",
      "With a validation score of: 0.832979851538\n",
      "And a train score of: 0.9872645264\n"
     ]
    }
   ],
   "source": [
    "ravel_index = np.argmax(valid_score)\n",
    "best_n_estimators_index = int(ravel_index / valid_score.shape[1])\n",
    "best_max_depth_index = ravel_index % valid_score.shape[1]\n",
    "\n",
    "best_n_estimators = parameters['n_estimators'][best_n_estimators_index]\n",
    "best_max_depth = parameters['max_depth'][best_max_depth_index]\n",
    "\n",
    "print('The best number of trees is:', best_n_estimators)\n",
    "print('The best maximal tree depth is:', best_max_depth)\n",
    "print('With a validation score of:', valid_score[best_n_estimators_index, best_max_depth_index])\n",
    "print('And a train score of:', train_score[best_n_estimators_index, best_max_depth_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pseudo optimal random forest training\n",
    "\n",
    "Now we train again a random forest classifier on our training data with those pseudo optimal parameters in order to be able to carry out prediction with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "opt_rand_forest = RandomForestClassifier(n_estimators=best_n_estimators, max_depth=best_max_depth, verbose = 1)\n",
    "opt_rand_forest.fit(train_vectors, train_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test score\n",
    "\n",
    "Now we are able to compute the score of the optimized random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score = opt_rand_forest.score(test_vectors, test_target)\n",
    "print('The test score is:', test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can remark that the test score is less than both the validation and train scores. This is conformed with what we could expect given that the model is trained from train set and then "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = opt_rand_forest.predict(test_vectors)\n",
    "confusion_matrix = sklearn.metrics.confusion_matrix(test_target, y_pred_test, labels=range(20), sample_weight=None)\n",
    "confusion_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we modify the confusion matrix so that each of its rows are normalized according to the number of true elements of each label in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "div = confusion_matrix.sum(axis=1)\n",
    "div = np.column_stack([div]*20)\n",
    "normalized_confusion = confusion_matrix / div"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the confusion matrix is normalized we plot it along with a dictionary of the class indices in order to better read the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(newsgroups.target_names)\n",
    "[print(x,'->',labels[x]) for x in range(20)]\n",
    "fig = plt.figure(figsize=(9, 9))\n",
    "ax = fig.add_subplot(111)\n",
    "plot = ax.matshow(normalized_confusion)\n",
    "fig.colorbar(plot)\n",
    "plt.title('Normalized confusion matrix of the Random Forest')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix graphically shows that the classifier is a good prediction model. Indeed we can see that the diagonal elements of the matrix show much higher ratios than the non diagonal elements. It shows that the number of true answers is quite high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature analyzis\n",
    "\n",
    "The idea now is to analyze the features that had the greatest important when constructing the decision trees of the random forest. Every feature is assigned a score in the `feature_importances_`'s attribute of RandomForest. Therefore we are going to use this attribute in order to get the words that were the most used in order to classify the newspapers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46061     0.005640\n",
       "165812    0.005572\n",
       "55485     0.005127\n",
       "65684     0.004817\n",
       "139570    0.004690\n",
       "80391     0.004252\n",
       "52100     0.004173\n",
       "85770     0.004093\n",
       "145613    0.003817\n",
       "92333     0.003498\n",
       "41895     0.003209\n",
       "44285     0.003203\n",
       "69924     0.003128\n",
       "116858    0.003078\n",
       "52328     0.003054\n",
       "54421     0.002999\n",
       "78332     0.002993\n",
       "82049     0.002770\n",
       "71043     0.002754\n",
       "151673    0.002704\n",
       "dtype: float64"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_imp = opt_rand_forest.feature_importances_\n",
    "feat_serie = pd.Series(feat_imp)\n",
    "sorted_feat_serie = feat_serie.sort_values(ascending = False).head(20)\n",
    "sorted_feat_serie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we have the 20 features that served the most for classifying the data. We are now going to retrieve the real English word behind the indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bike',\n",
       " 'windows',\n",
       " 'clipper',\n",
       " 'dod',\n",
       " 'sale',\n",
       " 'god',\n",
       " 'car',\n",
       " 'hockey',\n",
       " 'space',\n",
       " 'israel',\n",
       " 'athos',\n",
       " 'baseball',\n",
       " 'encryption',\n",
       " 'nhl',\n",
       " 'cars',\n",
       " 'christian',\n",
       " 'game',\n",
       " 'gun',\n",
       " 'escrow',\n",
       " 'team']"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[vectorizer.get_feature_names()[x] for x in sorted_feat_serie.index]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore above we have the 20 features that helped the most classifying our dataset of documents in the 20 classes defined in `newsgroups.target_names`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
