{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging of the 4 leaks folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paradise papers are not included for the moment.\n",
    "This short code makes correspond the new version of the dataset with the former one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaks= ['bahamas_leaks', 'offshore_leaks', 'panama_papers'] #paradise_papers\n",
    "month_code = '2017-11-17'\n",
    "\n",
    "edges_df = pd.DataFrame([])\n",
    "addresses_df = pd.DataFrame([])\n",
    "entities_df = pd.DataFrame([])\n",
    "intermediaries_df = pd.DataFrame([])\n",
    "officers_df = pd.DataFrame([])\n",
    "\n",
    "\n",
    "for leak in leaks:\n",
    "    edges_df = edges_df.append(pd.read_csv('./data/data_csv/csv_' + leak + '.' +\n",
    "                                           month_code + '/' + leak + '.edges.csv', dtype=object))\n",
    "    \n",
    "    addresses_df = addresses_df.append(pd.read_csv('./data/data_csv/csv_' + leak + '.' + \n",
    "                                               month_code + '/' + leak + '.nodes.address.csv', dtype=object))\n",
    "    \n",
    "    entities_df = entities_df.append(pd.read_csv('./data/data_csv/csv_' + leak + '.' + \n",
    "                                           month_code + '/' + leak + '.nodes.entity.csv', dtype=object))\n",
    "    \n",
    "    intermediaries_df = intermediaries_df.append(pd.read_csv('./data/data_csv/csv_' + leak + '.' + \n",
    "                                           month_code + '/' + leak + '.nodes.intermediary.csv', dtype=object))\n",
    "    \n",
    "    officers_df = officers_df.append(pd.read_csv('./data/data_csv/csv_' + leak + '.' + \n",
    "                                           month_code + '/' + leak + '.nodes.officer.csv', dtype=object))\n",
    "    \n",
    "    \n",
    "edges_df.index = range(len(edges_df))\n",
    "edges_df.to_csv('./data/data_csv/all_edges.csv')\n",
    "addresses_df.index = range(len(addresses_df))\n",
    "addresses_df.columns = addresses_df.columns.str.replace('n\\.','')\n",
    "addresses_df.to_csv('./data/data_csv/Addresses.csv')\n",
    "entities_df.index = range(len(entities_df))\n",
    "entities_df.columns = entities_df.columns.str.replace('n\\.','')\n",
    "entities_df.to_csv('./data/data_csv/Entities.csv')\n",
    "intermediaries_df.index = range(len(intermediaries_df))\n",
    "intermediaries_df.columns = intermediaries_df.columns.str.replace('n\\.','')\n",
    "intermediaries_df.to_csv('./data/data_csv/Intermediaries.csv')\n",
    "officers_df.index = range(len(officers_df))\n",
    "officers_df.columns = officers_df.columns.str.replace('n\\.','')\n",
    "officers_df.to_csv('./data/data_csv/Officers.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and cleaning of the dataset\n",
    "\n",
    "Reading of the different parts of the dataset. There are 4 different files that are converted into pandas DataFrames:\n",
    "- `Entities.csv`, `Officers.csv`, `Intermediaries.csv` are dedicated to the three types of actors encountered in the database. Entities refer to asset providers and officers to financial actors (company, private client, ...). Intermediaries refer to actors putting clients and financial service providers in contact.\n",
    "- `Addresses.csv` describe all the addresses contained in the database those addresses are linked to officers.\n",
    "- `all_edges.csv` describe the relationships between the items of the database described before, that are entities, officers, intermediaries and addresses. Four different kinds of relationships are described in this dataset: 'registered address', 'shareholder of', 'beneficiary of' and 'intermediary of'.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = pd.read_csv(\"./data/data_csv/Entities.csv\", dtype = 'object')\n",
    "intermediaries = pd.read_csv(\"./data/data_csv/Intermediaries.csv\", dtype = 'object')\n",
    "officers = pd.read_csv(\"./data/data_csv/Officers.csv\", dtype = 'object')\n",
    "addresses = pd.read_csv(\"./data/data_csv/Addresses.csv\", dtype = 'object')\n",
    "all_edges = pd.read_csv(\"./data/data_csv/all_edges.csv\", dtype = 'object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset description\n",
    "\n",
    "Now we print the DataFrames' columns and size in order to have a rough idea of their content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entities:\n",
      "\tshape: (495038, 19)\n",
      "\tcolumns: Index(['Unnamed: 0', 'labels(n)', 'valid_until', 'country_codes', 'countries',\n",
      "       'node_id', 'sourceID', 'address', 'name', 'jurisdiction_description',\n",
      "       'service_provider', 'jurisdiction', 'closed_date', 'incorporation_date',\n",
      "       'ibcRUC', 'type', 'status', 'company_type', 'note'],\n",
      "      dtype='object')\n",
      "\n",
      "intermediaries:\n",
      "\tshape: (24177, 19)\n",
      "\tcolumns: Index(['Unnamed: 0', 'labels(n)', 'valid_until', 'country_codes', 'countries',\n",
      "       'node_id', 'sourceID', 'address', 'name', 'jurisdiction_description',\n",
      "       'service_provider', 'jurisdiction', 'closed_date', 'incorporation_date',\n",
      "       'ibcRUC', 'type', 'status', 'company_type', 'note'],\n",
      "      dtype='object')\n",
      "\n",
      "officers:\n",
      "\tshape: (370854, 19)\n",
      "\tcolumns: Index(['Unnamed: 0', 'labels(n)', 'valid_until', 'country_codes', 'countries',\n",
      "       'node_id', 'sourceID', 'address', 'name', 'jurisdiction_description',\n",
      "       'service_provider', 'jurisdiction', 'closed_date', 'incorporation_date',\n",
      "       'ibcRUC', 'type', 'status', 'company_type', 'note'],\n",
      "      dtype='object')\n",
      "\n",
      "addresses:\n",
      "\tshape: (151605, 19)\n",
      "\tcolumns: Index(['Unnamed: 0', 'labels(n)', 'valid_until', 'country_codes', 'countries',\n",
      "       'node_id', 'sourceID', 'address', 'name', 'jurisdiction_description',\n",
      "       'service_provider', 'jurisdiction', 'closed_date', 'incorporation_date',\n",
      "       'ibcRUC', 'type', 'status', 'company_type', 'note'],\n",
      "      dtype='object')\n",
      "\n",
      "all_edges:\n",
      "\tshape: (1484685, 8)\n",
      "\tcolumns: Index(['Unnamed: 0', 'node_1', 'rel_type', 'node_2', 'r.sourceID',\n",
      "       'r.valid_until', 'r.start_date', 'r.end_date'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print('entities:')\n",
    "print('\\tshape:', entities.shape)\n",
    "print('\\tcolumns:', entities.columns)\n",
    "print()\n",
    "\n",
    "print('intermediaries:')\n",
    "print('\\tshape:', intermediaries.shape)\n",
    "print('\\tcolumns:', intermediaries.columns)\n",
    "print()\n",
    "\n",
    "print('officers:')\n",
    "print('\\tshape:', officers.shape)\n",
    "print('\\tcolumns:', officers.columns)\n",
    "print()\n",
    "\n",
    "print('addresses:')\n",
    "print('\\tshape:', addresses.shape)\n",
    "print('\\tcolumns:', addresses.columns)\n",
    "print()\n",
    "\n",
    "print('all_edges:')\n",
    "print('\\tshape:', all_edges.shape)\n",
    "print('\\tcolumns:', all_edges.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning up\n",
    "\n",
    "The `entities`, `intermediaries` and `officers`' rows whose columns `name` and `countries` contains a NaN value are dropped because these rows will not be exploitable for the analysis. We also drop `addresses`' rows whose `address` column has a NaN value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187862 rows dropped in entities\n",
      "1909 rows dropped in intermediaries\n",
      "158254 rows dropped in officers\n",
      "1247 rows dropped in addresses\n"
     ]
    }
   ],
   "source": [
    "original_num_row = entities.shape[0]\n",
    "entities = entities[entities['name'].notnull()]\n",
    "entities = entities[entities['countries'].notnull()]\n",
    "entities = entities[entities['country_codes'] != 'XXX']\n",
    "entities[entities['country_codes'] == 'REU'] = 'FRA'\n",
    "entities[entities['country_codes'] == 'MTQ'] = 'FRA'\n",
    "final_num_row = entities.shape[0]\n",
    "print(original_num_row - final_num_row, 'rows dropped in entities')\n",
    "\n",
    "original_num_row = intermediaries.shape[0]\n",
    "intermediaries = intermediaries[intermediaries['name'].notnull()]\n",
    "intermediaries = intermediaries[intermediaries['countries'].notnull()]\n",
    "intermediaries = intermediaries[intermediaries['country_codes'] != 'XXX']\n",
    "intermediaries[intermediaries['country_codes'] == 'REU'] = 'FRA'\n",
    "intermediaries[intermediaries['country_codes'] == 'MTQ'] = 'FRA'\n",
    "final_num_row = intermediaries.shape[0]\n",
    "print(original_num_row - final_num_row, 'rows dropped in intermediaries')\n",
    "\n",
    "original_num_row = officers.shape[0]\n",
    "officers = officers[officers['name'].notnull()]\n",
    "officers = officers[officers['countries'].notnull()]\n",
    "officers = officers[officers['country_codes'] != 'XXX']\n",
    "officers[officers['country_codes'] == 'REU'] = 'FRA'\n",
    "officers[officers['country_codes'] == 'MTQ'] = 'FRA'\n",
    "final_num_row = officers.shape[0]\n",
    "print(original_num_row - final_num_row, 'rows dropped in officers')\n",
    "\n",
    "original_num_row = addresses.shape[0]\n",
    "addresses = addresses[addresses['address'].notnull()]\n",
    "addresses = addresses[addresses['countries'].notnull()]\n",
    "addresses = addresses[addresses['country_codes'] != 'XXX']\n",
    "addresses[addresses['country_codes'] == 'REU'] = 'FRA'\n",
    "addresses[addresses['country_codes'] == 'MTQ'] = 'FRA'\n",
    "final_num_row = addresses.shape[0]\n",
    "print(original_num_row - final_num_row, 'rows dropped in addresses')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing clean datasets in new files\n",
    "\n",
    "In order to not have to carry out the preprocessing again we write the the DataFrames in new files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities.to_csv('./data/data_clean_csv/entities_clean.csv', index = False)\n",
    "intermediaries.to_csv('./data/data_clean_csv/intermediaries_clean.csv', index = False)\n",
    "officers.to_csv('./data/data_clean_csv/officers_clean.csv', index = False)\n",
    "addresses.to_csv('./data/data_clean_csv/addresses_clean.csv', index = False)\n",
    "all_edges.to_csv('./data/data_clean_csv/all_edges_clean.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
